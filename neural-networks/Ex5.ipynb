{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for NN with 10 hidden neurons\n",
      "epoch:  0  loss:  18586.115234375\n",
      "epoch:  100  loss:  18586.115234375\n",
      "epoch:  200  loss:  18586.115234375\n",
      "epoch:  300  loss:  18586.115234375\n",
      "epoch:  400  loss:  18586.115234375\n",
      "epoch:  500  loss:  18586.115234375\n",
      "epoch:  600  loss:  18586.115234375\n",
      "epoch:  700  loss:  18586.115234375\n",
      "epoch:  800  loss:  18586.115234375\n",
      "epoch:  900  loss:  18586.115234375\n",
      "epoch:  1000  loss:  18586.115234375\n",
      "epoch:  1100  loss:  18586.115234375\n",
      "Train loss:  18586.115234375\n",
      "Test loss :  50631.34375\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import cm\n",
    "\n",
    "SEED = 5218\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "TRAIN_DATA_RATIO = 0.8\n",
    "\n",
    "ages = [15, 15, 15, 18, 28, 29, 37, 37, 44, 50, 50, 60, 61, 64, 65, 65, 72, 75, 75, 82, 85, 91, 91, 97, 98, 125, 142,\n",
    "        142, 147, 147, 150, 159, 165, 183, 192, 195, 218, 218, 219, 224, 225, 227, 232, 232, 237, 246, 258, 276, 285,\n",
    "        300, 301, 305, 312, 317, 338, 347, 354, 357, 375, 394, 513, 535, 554, 591, 648, 660, 705, 723, 756, 768, 860,\n",
    "        ]\n",
    "\n",
    "weights = [21.66, 22.75, 22.3, 31.25, 44.79, 40.55, 50.25, 46.88, 52.03, 63.47, 61.13, 81, 73.09, 79.09, 79.51, 65.31,\n",
    "           71.9, 86.1, 94.6, 92.5, 105, 101.7, 102.9, 110, 104.3, 134.9, 130.68, 140.58, 155.3, 152.2, 144.5, 142.15,\n",
    "           139.81, 153.22, 145.72, 161.1, 174.18, 173.03, 173.54, 178.86, 177.68, 173.73, 159.98, 161.29, 187.07,\n",
    "           176.13, 183.4, 186.26, 189.66, 186.09, 186.7, 186.8, 195.1, 216.41, 203.23, 188.38, 189.7, 195.31, 202.63,\n",
    "           224.82, 203.3, 209.7, 233.9, 234.7, 244.3, 231, 242.4, 230.77, 242.57, 232.12, 246.7,\n",
    "           ]\n",
    "data_size = len(ages)\n",
    "\n",
    "\n",
    "def test_divider(data):\n",
    "    return int(TRAIN_DATA_RATIO * len(data))\n",
    "\n",
    "\n",
    "x_raw_train = np.reshape(ages[:test_divider(ages)], (test_divider(ages), 1))\n",
    "y_raw_train = np.reshape(weights[:test_divider(weights)], (test_divider(weights), 1))\n",
    "\n",
    "x_raw_test = np.reshape(ages[test_divider(ages):], (data_size - test_divider(ages), 1))\n",
    "y_raw_test = np.reshape(weights[test_divider(weights):], (data_size - test_divider(weights), 1))\n",
    "\n",
    "\n",
    "def main(number_of_neurons):\n",
    "    print(f'Running for NN with', number_of_neurons, 'hidden neurons')\n",
    "    # Defining input size, hidden layer size, output size and batch size respectively\n",
    "    n_in, n_h, n_out, batch_size = 1, number_of_neurons, 1, 5000\n",
    "\n",
    "    # Create training data\n",
    "    x_train = torch.FloatTensor(x_raw_train)\n",
    "    y_train = torch.FloatTensor(y_raw_train)\n",
    "\n",
    "    # Create test data\n",
    "    x_test = torch.FloatTensor(x_raw_test)\n",
    "    y_test = torch.FloatTensor(y_raw_test)\n",
    "\n",
    "    # Create the first model\n",
    "    model = nn.Sequential(nn.Linear(n_in, n_h),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(n_h, n_out),\n",
    "                          nn.ReLU())\n",
    "\n",
    "    # Construct the loss function\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # Construct the optimizer (Stochastic Gradient Descent in this case)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Gradient Descent\n",
    "    for epoch in range(1200):\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(x_train)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        if epoch % 100 == 0:\n",
    "            print('epoch: ', epoch, ' loss: ', loss.item())\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    y_pred_test = model(x_test)\n",
    "    test_loss = criterion(y_pred_test, y_test)\n",
    "\n",
    "    print('Train loss: ', loss.item())\n",
    "    print('Test loss : ', test_loss.item())\n",
    "\n",
    "\n",
    "# for x in range(1, 20, 2):\n",
    "#     main(x)\n",
    "\n",
    "main(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
